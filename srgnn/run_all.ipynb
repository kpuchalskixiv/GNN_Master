{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kacper/anaconda3/envs/gpu_torch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from main_pl import main as train_model\n",
    "from label_items_with_gmm import main as label_with_gmm\n",
    "from basic_cat_augmentation import main as label_with_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='yoochoose1_64'\n",
    "no_gmm=2\n",
    "augment_dist_flag=\"--augment-clusters\" #/'--augment-categories' or '' for i2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_str=f\"--epoch 2 --dataset {dataset} --validation --valid-portion 0.1 --lr-scheduler step --step 2 --lr-dc-step 2 --patience 5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset='yoochoose1_64', batchSize=100, hiddenSize=100, epoch=2, lr=0.001, lr_dc=0.1, lr_dc_step=2, lr_milestones=[2, 5, 8], l2=1e-05, step=2, patience=5, nonhybrid=False, validation=True, valid_portion=0.1, pretrained_embeddings=False, unfreeze_epoch=0, gmm=[], weight_init='normal', augment_matrix=False, augment_clusters=False, augment_old_run_id=None, augment_clip=0, augment_normalize=False, augment_raw=False, augment_p=1.0, augment_noise_p=1.0, augment_mean=0.01, augment_std=0.0, augment_categories=False, augment_nogmm=16, augment_gmm_init='k-means++', lr_scheduler='step', augment_prenormalize_distances=False)\n",
      "data masking start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:04<00:00, 15.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done masking\n",
      "data masking start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 214.68it/s]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done masking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkpuchalskixiv\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kacper/GNN_Master/srgnn/wandb/run-20240915_172009-q4bnw7ks</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kpuchalskixiv/GNN_master/runs/q4bnw7ks' target=\"_blank\">major-donkey-582</a></strong> to <a href='https://wandb.ai/kpuchalskixiv/GNN_master' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kpuchalskixiv/GNN_master' target=\"_blank\">https://wandb.ai/kpuchalskixiv/GNN_master</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kpuchalskixiv/GNN_master/runs/q4bnw7ks' target=\"_blank\">https://wandb.ai/kpuchalskixiv/GNN_master/runs/q4bnw7ks</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kacper/anaconda3/envs/gpu_torch/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:390: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type         | Params\n",
      "---------------------------------------\n",
      "0 | model | SessionGraph | 3.9 M \n",
      "---------------------------------------\n",
      "3.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.9 M     Total params\n",
      "15.640    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 3328/3328 [01:22<00:00, 40.56it/s, v_num=w7ks, train_loss=4.060, val_loss=4.580, val_hit=66.60, val_mrr=29.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 3328/3328 [01:22<00:00, 40.53it/s, v_num=w7ks, train_loss=4.060, val_loss=4.580, val_hit=66.60, val_mrr=29.60]\n",
      "Finished training. Run id:  q4bnw7ks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████</td></tr><tr><td>scheduler_lr</td><td>▁▁</td></tr><tr><td>train_loss</td><td>█▇▆▇▄▆▄▅▄▄▄▄▃▃▃▃▃▄▃▃▃▂▄▃▂▃▃▂▂▃▃▂▂▂▃▁▃▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_hit</td><td>▁█</td></tr><tr><td>val_loss</td><td>█▁</td></tr><tr><td>val_mrr</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>scheduler_lr</td><td>0.001</td></tr><tr><td>train_loss</td><td>4.60075</td></tr><tr><td>trainer/global_step</td><td>6655</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">major-donkey-582</strong> at: <a href='https://wandb.ai/kpuchalskixiv/GNN_master/runs/q4bnw7ks' target=\"_blank\">https://wandb.ai/kpuchalskixiv/GNN_master/runs/q4bnw7ks</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240915_172009-q4bnw7ks/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rid=train_model(\n",
    "    flag_str.strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rid='q4bnw7ks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': 'yoochoose1_64', 'batchSize': 100, 'hiddenSize': 100, 'epoch': 2, 'lr': 0.001, 'lr_dc': 0.1, 'lr_dc_step': 2, 'l2': 1e-05, 'step': 2, 'patience': 5, 'nonhybrid': False, 'validation': True, 'valid_portion': 0.1, 'pretrained_embedings': False, 'unfreeze_epoch': 0, 'gmm': [], 'augment_matrix': False, 'augment_clusters': False, 'augment_old_run_id': None, 'augment_clip': 0, 'augment_normalize': False, 'augment_raw': False, 'weight_init': 'normal', 'augment_categories': False, 'augment_nogmm': 16, 'augment_p': 1.0, 'augment_mean': 0.01, 'augment_std': 0.0, 'augment_gmm_init': 'k-means++', 'augment_prenormalize_distances': False, 'augment_noise_p': 1.0}\n",
      "(array([0, 1]), array([   18, 37466]))\n"
     ]
    }
   ],
   "source": [
    "if augment_dist_flag==\"--augment-clusters\":\n",
    "    gmm_label_flags=f\"--run-id {rid} --no-clusters {no_gmm}\"\n",
    "    label_with_gmm(gmm_label_flags.strip())\n",
    "\n",
    "elif augment_dist_flag=='--augment-categories':\n",
    "    cat_label_flags=f\"--run-id {rid}\"\n",
    "    label_with_categories(cat_label_flags.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_model_flags=f\"--epoch 2 --dataset {dataset} --validation --valid-portion 0.1 --lr-scheduler step --step 2 --lr-dc-step 2 --patience 4 --augment-matrix --augment-old-run-id {rid} {augment_dist_flag} --augment-std 0.01 --augment-normalize --augment-p 0.5 --l2 0.000001 --augment-nogmm {no_gmm}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset='yoochoose1_64', batchSize=100, hiddenSize=100, epoch=2, lr=0.001, lr_dc=0.1, lr_dc_step=2, lr_milestones=[2, 5, 8], l2=1e-06, step=2, patience=4, nonhybrid=False, validation=True, valid_portion=0.1, pretrained_embeddings=False, unfreeze_epoch=0, gmm=[], weight_init='normal', augment_matrix=True, augment_clusters=True, augment_old_run_id='q4bnw7ks', augment_clip=0, augment_normalize=True, augment_raw=False, augment_p=0.5, augment_noise_p=1.0, augment_mean=0.01, augment_std=0.01, augment_categories=False, augment_nogmm=2, augment_gmm_init='k-means++', lr_scheduler='step', augment_prenormalize_distances=False)\n",
      "data masking start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:04<00:00, 15.36it/s]\n",
      "/home/kacper/GNN_Master/srgnn/srgnn_datasets.py:450: RuntimeWarning: divide by zero encountered in divide\n",
      "  self.cluster_distances = 1 / self.cluster_distances\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done masking\n",
      "data masking start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 217.02it/s]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done masking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kacper/GNN_Master/srgnn/wandb/run-20240915_173605-0edv4xqy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kpuchalskixiv/GNN_master/runs/0edv4xqy' target=\"_blank\">sweet-bee-583</a></strong> to <a href='https://wandb.ai/kpuchalskixiv/GNN_master' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kpuchalskixiv/GNN_master' target=\"_blank\">https://wandb.ai/kpuchalskixiv/GNN_master</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kpuchalskixiv/GNN_master/runs/0edv4xqy' target=\"_blank\">https://wandb.ai/kpuchalskixiv/GNN_master/runs/0edv4xqy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kacper/anaconda3/envs/gpu_torch/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:390: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type         | Params\n",
      "---------------------------------------\n",
      "0 | model | SessionGraph | 3.9 M \n",
      "---------------------------------------\n",
      "3.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.9 M     Total params\n",
      "15.640    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 3328/3328 [01:21<00:00, 40.93it/s, v_num=4xqy, train_loss=4.220, val_loss=4.520, val_hit=67.10, val_mrr=30.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 3328/3328 [01:21<00:00, 40.89it/s, v_num=4xqy, train_loss=4.220, val_loss=4.520, val_hit=67.10, val_mrr=30.40]\n",
      "Finished training. Run id:  0edv4xqy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████</td></tr><tr><td>scheduler_lr</td><td>▁▁</td></tr><tr><td>train_loss</td><td>█▇▇▅▅▅▄▄▄▄▃▃▄▃▄▃▃▃▃▃▂▁▂▂▂▂▂▂▂▂▂▁▂▁▂▂▂▁▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_hit</td><td>▁█</td></tr><tr><td>val_loss</td><td>█▁</td></tr><tr><td>val_mrr</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>scheduler_lr</td><td>0.001</td></tr><tr><td>train_loss</td><td>4.51797</td></tr><tr><td>trainer/global_step</td><td>6655</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sweet-bee-583</strong> at: <a href='https://wandb.ai/kpuchalskixiv/GNN_master/runs/0edv4xqy' target=\"_blank\">https://wandb.ai/kpuchalskixiv/GNN_master/runs/0edv4xqy</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240915_173605-0edv4xqy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_=train_model(\n",
    "    augmented_model_flags.strip()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
