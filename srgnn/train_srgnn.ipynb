{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "654bef7e",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63f9d196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from utils import split_validation\n",
    "from srgnn_pl import SRGNN_model, SRGNN_Map_Dataset\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "import wandb\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "import torch.utils.data as data_utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b978282",
   "metadata": {},
   "outputs": [],
   "source": [
    "class fake_parser():\n",
    "    def __init__(self,\n",
    "                 dataset='yoochoose1_64',\n",
    "                 batchSize=128,\n",
    "                 hiddenSize=128,\n",
    "                 epoch=30,\n",
    "                 lr=1e-3,\n",
    "                 lr_dc=0.1,\n",
    "                 lr_dc_step=3,\n",
    "                 l2=1e-5,\n",
    "                 step=1,\n",
    "                 patience=10,\n",
    "                 nonhybrid=False,\n",
    "                 validation=True,\n",
    "                 valid_portion=0.1,\n",
    "                 pretrained_embedings=False):\n",
    "        self.dataset=dataset\n",
    "        self.batchSize=batchSize\n",
    "        self.hiddenSize=hiddenSize\n",
    "        self.epoch=epoch\n",
    "        self.lr=lr\n",
    "        self.lr_dc=lr_dc\n",
    "        self.lr_dc_step=lr_dc_step\n",
    "        self.l2=l2\n",
    "        self.step=step\n",
    "        self.patience=patience\n",
    "        self.nonhybrid=nonhybrid\n",
    "        self.validation=validation\n",
    "        self.valid_portion=valid_portion\n",
    "        self.pretrained_embedings=pretrained_embedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07a118e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=fake_parser(step=3, batchSize=128, hiddenSize=256, epoch=60, validation=True, valid_portion=0.2,\n",
    "                nonhybrid=True,\n",
    "               dataset='yoochoose_custom_augmented_5050')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bea484fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pickle.load(open('../datasets/' + opt.dataset  + '/train.txt', 'rb'))\n",
    "if opt.validation:\n",
    "    train_data, valid_data = split_validation(train_data, opt.valid_portion)\n",
    "else:\n",
    "    test_data = pickle.load(open('../datasets/' + opt.dataset + '/test.txt', 'rb'))\n",
    "\n",
    "if opt.dataset == 'diginetica':\n",
    "    n_node = 43098\n",
    "elif opt.dataset == 'yoochoose1_64' or opt.dataset == 'yoochoose1_4':\n",
    "    n_node = 37484\n",
    "elif opt.dataset == 'yoochoose_custom':\n",
    "    n_node = 28583\n",
    "elif opt.dataset == 'yoochoose_custom_augmented':\n",
    "    n_node = 27809\n",
    "elif opt.dataset == 'yoochoose_custom_augmented_5050':\n",
    "    n_node = 27807\n",
    "else:\n",
    "    n_node = 310\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRGNN_sampler(data_utils.Sampler):\n",
    "    def __init__(self, dataset, batch_size, shuffle=False, drop_last=False):\n",
    "        self.dataset=dataset\n",
    "        self.batch_size=batch_size\n",
    "        self.shuffle=shuffle\n",
    "        self.drop_last=drop_last\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.length\n",
    "    \n",
    "    def __iter__(self):\n",
    "        order=np.arange(len(self))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(order)\n",
    "        if len(self)%self.batch_size:\n",
    "            for i in range(0, len(self)-self.batch_size, self.batch_size):\n",
    "                yield order[i:i+self.batch_size]\n",
    "            if not self.drop_last:\n",
    "                yield order[-(len(self)%self.batch_size):]\n",
    "        else:\n",
    "            for i in range(0, len(self), self.batch_size):\n",
    "                yield order[i:i+self.batch_size]\n",
    "       # raise IndexError('Done iterating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4c8bb63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data masking start\n",
      "data masking 1\n",
      "data masking 2\n",
      "data masking 3\n",
      "done masking\n",
      "data masking start\n",
      "data masking 1\n",
      "data masking 2\n",
      "data masking 3\n",
      "done masking\n"
     ]
    }
   ],
   "source": [
    "train_dataset=SRGNN_Map_Dataset(train_data, shuffle=True)\n",
    "del train_data\n",
    "val_dataset=SRGNN_Map_Dataset(valid_data)\n",
    "del valid_data\n",
    "\n",
    "train_dataloader=DataLoader(train_dataset, \n",
    "                            #batch_size=opt.batchSize, \n",
    "                            num_workers=os.cpu_count(),  \n",
    "                          #  worker_init_fn=worker_init_fn, \n",
    "                            sampler=SRGNN_sampler(train_dataset, opt.batchSize, shuffle=True, drop_last=False)\n",
    "                            #drop_last=\n",
    "                            )\n",
    "#del train_dataset\n",
    "val_dataloader=DataLoader(val_dataset, \n",
    "                          #batch_size=opt.batchSize, \n",
    "                          num_workers=os.cpu_count(), \n",
    "                          sampler=SRGNN_sampler(val_dataset, opt.batchSize, shuffle=False, drop_last=False)\n",
    "\n",
    "                        #  worker_init_fn=worker_init_fn\n",
    "                         )\n",
    "#del val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "38158a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=SRGNN_model(opt, n_node, \n",
    "                  init_embeddings=None,\n",
    "                  **(opt.__dict__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f66d9f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger = pl.loggers.WandbLogger(project='GNN_master',entity=\"kpuchalskixiv\",\n",
    "                                      log_model=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer=pl.Trainer(max_epochs=60,\n",
    "                   limit_train_batches=train_dataset.length//opt.batchSize,\n",
    "                   limit_val_batches=val_dataset.length//opt.batchSize,\n",
    "                   callbacks=[\n",
    "                              EarlyStopping(monitor=\"val_loss\", patience=6, mode=\"min\", check_finite=True)],\n",
    "                   logger=wandb_logger\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ecd6ea5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kacper/anaconda3/envs/gpu_torch/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /home/kacper/SR-GNN/pytorch_code/lightning_logs/version_15/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type         | Params\n",
      "---------------------------------------\n",
      "0 | model | SessionGraph | 10.6 M\n",
      "---------------------------------------\n",
      "10.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.6 M    Total params\n",
      "42.593    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789e7f92bbf041679e2986fd99d23b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/kacper/anaconda3/envs/gpu_torch/lib/python3.11/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/kacper/anaconda3/envs/gpu_torch/lib/python3.11/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/kacper/anaconda3/envs/gpu_torch/lib/python3.11/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/home/kacper/anaconda3/envs/gpu_torch/lib/python3.11/shutil.py\", line 738, in rmtree\n",
      "    onerror(os.rmdir, path, sys.exc_info())\n",
      "  File \"/home/kacper/anaconda3/envs/gpu_torch/lib/python3.11/shutil.py\", line 736, in rmtree\n",
      "    os.rmdir(path, dir_fd=dir_fd)\n",
      "OSError: [Errno 39] Directory not empty: '/tmp/pymp-a137fgfd'\n",
      "/home/kacper/anaconda3/envs/gpu_torch/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:438: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c81aea6a6dd64f2ba5f54c9e0741d204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model=model, \n",
    "            train_dataloaders=train_dataloader,\n",
    "            val_dataloaders=val_dataloader\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a74c588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "609995c22aab4b7a9acbe51995e92872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='481.518 MB of 481.518 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
