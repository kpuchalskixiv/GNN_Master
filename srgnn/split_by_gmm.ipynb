{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from srgnn_pl import SRGNN_model, SRGNN_Map_Dataset, SRGNN_sampler\n",
    "from utils import fake_parser\n",
    "import os\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from utils import split_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data & models loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id='run-20240404_162708-ekuo66ei'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': 'diginetica', 'batchSize': 100, 'hiddenSize': 100, 'epoch': 60, 'lr': 0.001, 'lr_dc': 0.1, 'lr_dc_step': 3, 'l2': 1e-05, 'step': 3, 'patience': 10, 'nonhybrid': False, 'validation': True, 'valid_portion': 0.1, 'pretrained_embedings': False, 'unfreeze_epoch': 1}\n"
     ]
    }
   ],
   "source": [
    "with open(f\"./wandb/{run_id}/files/config.yaml\", \"r\") as stream:\n",
    "        config=yaml.safe_load(stream)\n",
    "\n",
    "keys=list(config.keys())\n",
    "for k in keys:\n",
    "    if k not in fake_parser().__dict__.keys():\n",
    "        del config[k]\n",
    "    else:\n",
    "        config[k]=config[k]['value']\n",
    "\n",
    "opt=fake_parser(**config)\n",
    "print(opt.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('medium')\n",
    "model=SRGNN_model.load_from_checkpoint(f\"./GNN_master/{run_id.split('-')[-1]}/checkpoints/\"+\n",
    "                                       os.listdir(f\"./GNN_master/{run_id.split('-')[-1]}/checkpoints/\")[0], opt=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pickle.load(open('../datasets/' + opt.dataset + '/train.txt', 'rb'))\n",
    "\n",
    "if opt.dataset == 'diginetica':\n",
    "    n_node = 43098\n",
    "elif opt.dataset == 'yoochoose1_64' or opt.dataset == 'yoochoose1_4':\n",
    "    n_node = 37484\n",
    "\n",
    "elif opt.dataset == 'yoochoose_custom':\n",
    "    n_node = 28583\n",
    "elif opt.dataset == 'yoochoose_custom_augmented':\n",
    "    n_node = 27809\n",
    "elif opt.dataset == 'yoochoose_custom_augmented_5050':\n",
    "    n_node = 27807\n",
    "else:\n",
    "    n_node = 310"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data masking start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:04<00:00, 15.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done masking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#train_data, valid_data = split_validation(train_data, opt.valid_portion)\n",
    "train_dataset=SRGNN_Map_Dataset(train_data, shuffle=False)\n",
    "del train_data\n",
    "\n",
    "\n",
    "train_dataloader=DataLoader(train_dataset, \n",
    "                            num_workers=os.cpu_count(),  \n",
    "                            sampler=SRGNN_sampler(train_dataset, opt.batchSize, shuffle=False, drop_last=False)\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "719470"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get session embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7195it [00:39, 180.55it/s]                          \n"
     ]
    }
   ],
   "source": [
    "session_emb=[]\n",
    "full_sessions=[]\n",
    "\n",
    "model.to('cuda')\n",
    "for batch in tqdm(train_dataloader, total=train_dataset.length//opt.batchSize):\n",
    "    batch=[b.to('cuda') for b in batch]\n",
    "    session_emb.append(model.get_session_embeddings(batch).cpu().detach().numpy())\n",
    "session_emb=np.concatenate(session_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gm=GaussianMixture(n_components=32, n_init=1, init_params='k-means++')\n",
    "    \n",
    "#session_labels=gm.fit_predict(session_emb)\n",
    "\n",
    "#with open(f'./GMMs/gmm_train_{gm.n_components}_{gm.init_params}_{opt.hiddenSize}_{opt.dataset}.gmm', 'wb') as gmm_file:\n",
    " #   pickle.dump(gm, gmm_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7195/7195 [00:30<00:00, 237.96it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(f'./GMMs/gmm_val_32_k-means++_{opt.hiddenSize}_{opt.dataset}.gmm', 'rb') as gmm_file:\n",
    "    gm=pickle.load(gmm_file)\n",
    "\n",
    "session_labels=[]\n",
    "for i in tqdm(range(ceil(session_emb.shape[0]/opt.batchSize))):\n",
    "    session_labels.append(gm.predict(session_emb[i*opt.batchSize: (i+1)*opt.batchSize]))\n",
    "session_labels=np.concatenate(session_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]),\n",
       " array([16375, 31844, 64105, 25735, 19175, 18734, 34522, 30188, 18952,\n",
       "        12248, 22416, 15068, 16726,  8075, 16541,  8161, 46793, 14993,\n",
       "        14732, 12508, 15022, 16677, 86932, 10982, 10554, 19269,  8198,\n",
       "        10390, 52984, 15348, 13931, 11292]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(session_labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/kacper/GNN_Master/srgnn/split_by_gmm.ipynb Cell 19\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kacper/GNN_Master/srgnn/split_by_gmm.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tsne\u001b[39m=\u001b[39mTSNE(\u001b[39m2\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/kacper/GNN_Master/srgnn/split_by_gmm.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m tsne_session_embeddings\u001b[39m=\u001b[39mtsne\u001b[39m.\u001b[39;49mfit_transform(session_emb)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kacper/GNN_Master/srgnn/split_by_gmm.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m fig \u001b[39m=\u001b[39m go\u001b[39m.\u001b[39mFigure()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kacper/GNN_Master/srgnn/split_by_gmm.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39munique(session_labels):\n",
      "File \u001b[0;32m~/anaconda3/envs/gpu_torch/lib/python3.12/site-packages/sklearn/utils/_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    294\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    296\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    297\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    298\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    300\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    301\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/gpu_torch/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/gpu_torch/lib/python3.12/site-packages/sklearn/manifold/_t_sne.py:1136\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1115\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit X into an embedded space and return that transformed output.\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m \n\u001b[1;32m   1117\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1133\u001b[0m \u001b[39m    Embedding of the training data in low-dimensional space.\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_params_vs_input(X)\n\u001b[0;32m-> 1136\u001b[0m embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X)\n\u001b[1;32m   1137\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_ \u001b[39m=\u001b[39m embedding\n\u001b[1;32m   1138\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_\n",
      "File \u001b[0;32m~/anaconda3/envs/gpu_torch/lib/python3.12/site-packages/sklearn/manifold/_t_sne.py:1026\u001b[0m, in \u001b[0;36mTSNE._fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[39m# Degrees of freedom of the Student's t-distribution. The suggestion\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[39m# degrees_of_freedom = n_components - 1 comes from\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[39m# \"Learning a Parametric Embedding by Preserving Local Structure\"\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m \u001b[39m# Laurens van der Maaten, 2009.\u001b[39;00m\n\u001b[1;32m   1024\u001b[0m degrees_of_freedom \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m-> 1026\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tsne(\n\u001b[1;32m   1027\u001b[0m     P,\n\u001b[1;32m   1028\u001b[0m     degrees_of_freedom,\n\u001b[1;32m   1029\u001b[0m     n_samples,\n\u001b[1;32m   1030\u001b[0m     X_embedded\u001b[39m=\u001b[39;49mX_embedded,\n\u001b[1;32m   1031\u001b[0m     neighbors\u001b[39m=\u001b[39;49mneighbors_nn,\n\u001b[1;32m   1032\u001b[0m     skip_num_points\u001b[39m=\u001b[39;49mskip_num_points,\n\u001b[1;32m   1033\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/gpu_torch/lib/python3.12/site-packages/sklearn/manifold/_t_sne.py:1078\u001b[0m, in \u001b[0;36mTSNE._tsne\u001b[0;34m(self, P, degrees_of_freedom, n_samples, X_embedded, neighbors, skip_num_points)\u001b[0m\n\u001b[1;32m   1075\u001b[0m \u001b[39m# Learning schedule (part 1): do 250 iteration with lower momentum but\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m \u001b[39m# higher learning rate controlled via the early exaggeration parameter\u001b[39;00m\n\u001b[1;32m   1077\u001b[0m P \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mearly_exaggeration\n\u001b[0;32m-> 1078\u001b[0m params, kl_divergence, it \u001b[39m=\u001b[39m _gradient_descent(obj_func, params, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mopt_args)\n\u001b[1;32m   1079\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n\u001b[1;32m   1080\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m   1081\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m[t-SNE] KL divergence after \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m iterations with early exaggeration: \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1082\u001b[0m         \u001b[39m%\u001b[39m (it \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, kl_divergence)\n\u001b[1;32m   1083\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/gpu_torch/lib/python3.12/site-packages/sklearn/manifold/_t_sne.py:402\u001b[0m, in \u001b[0;36m_gradient_descent\u001b[0;34m(objective, p0, it, n_iter, n_iter_check, n_iter_without_progress, momentum, learning_rate, min_gain, min_grad_norm, verbose, args, kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[39m# only compute the error when needed\u001b[39;00m\n\u001b[1;32m    400\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mcompute_error\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m check_convergence \u001b[39mor\u001b[39;00m i \u001b[39m==\u001b[39m n_iter \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 402\u001b[0m error, grad \u001b[39m=\u001b[39m objective(p, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    404\u001b[0m inc \u001b[39m=\u001b[39m update \u001b[39m*\u001b[39m grad \u001b[39m<\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m    405\u001b[0m dec \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39minvert(inc)\n",
      "File \u001b[0;32m~/anaconda3/envs/gpu_torch/lib/python3.12/site-packages/sklearn/manifold/_t_sne.py:283\u001b[0m, in \u001b[0;36m_kl_divergence_bh\u001b[0;34m(params, P, degrees_of_freedom, n_samples, n_components, angle, skip_num_points, verbose, compute_error, num_threads)\u001b[0m\n\u001b[1;32m    280\u001b[0m indptr \u001b[39m=\u001b[39m P\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mint64, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    282\u001b[0m grad \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(X_embedded\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m--> 283\u001b[0m error \u001b[39m=\u001b[39m _barnes_hut_tsne\u001b[39m.\u001b[39;49mgradient(\n\u001b[1;32m    284\u001b[0m     val_P,\n\u001b[1;32m    285\u001b[0m     X_embedded,\n\u001b[1;32m    286\u001b[0m     neighbors,\n\u001b[1;32m    287\u001b[0m     indptr,\n\u001b[1;32m    288\u001b[0m     grad,\n\u001b[1;32m    289\u001b[0m     angle,\n\u001b[1;32m    290\u001b[0m     n_components,\n\u001b[1;32m    291\u001b[0m     verbose,\n\u001b[1;32m    292\u001b[0m     dof\u001b[39m=\u001b[39;49mdegrees_of_freedom,\n\u001b[1;32m    293\u001b[0m     compute_error\u001b[39m=\u001b[39;49mcompute_error,\n\u001b[1;32m    294\u001b[0m     num_threads\u001b[39m=\u001b[39;49mnum_threads,\n\u001b[1;32m    295\u001b[0m )\n\u001b[1;32m    296\u001b[0m c \u001b[39m=\u001b[39m \u001b[39m2.0\u001b[39m \u001b[39m*\u001b[39m (degrees_of_freedom \u001b[39m+\u001b[39m \u001b[39m1.0\u001b[39m) \u001b[39m/\u001b[39m degrees_of_freedom\n\u001b[1;32m    297\u001b[0m grad \u001b[39m=\u001b[39m grad\u001b[39m.\u001b[39mravel()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tsne=TSNE(2)\n",
    "tsne_session_embeddings=tsne.fit_transform(session_emb)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for label in np.unique(session_labels):\n",
    "    label_embedding=tsne_session_embeddings[session_labels==label]\n",
    "    fig.add_trace(go.Scatter(x=label_embedding[:,0], y=label_embedding[:,1], name=str(label), mode='markers'))\n",
    "\n",
    "fig.update_layout(title='TSNE reduced session embeddings with GM',\n",
    "                  margin=dict(l=40, r=40, t=40, b=40),\n",
    "                  width=1000, height=800)\n",
    "fig.write_html(f'./images/all_train_sessions_{opt.dataset}_{opt.hiddenSize}.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_dataloader\n",
    "del train_dataset\n",
    "train_data = pickle.load(open('../datasets/' + opt.dataset  + '/train.txt', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 74.88it/s]\n"
     ]
    }
   ],
   "source": [
    "for cluster in tqdm(np.unique(session_labels)):\n",
    "    idxs=np.arange(session_labels.shape[0])[session_labels==cluster]\n",
    "    cluster_sessions=[]\n",
    "    cluster_targets=[]\n",
    "    for i in idxs:\n",
    "        cluster_sessions.append(train_data[0][i])\n",
    "        cluster_targets.append(train_data[1][i])\n",
    "    with open(f'../datasets/{opt.dataset}/gm_train_splits_{opt.hiddenSize}_{run_id.split('-')[-1]}/train_{cluster}.txt', 'wb') as cluster_file:\n",
    "        pickle.dump((cluster_sessions, cluster_targets), cluster_file)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
